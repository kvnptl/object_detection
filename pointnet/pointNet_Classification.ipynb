{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpvL68OfBEQC"
      },
      "source": [
        "# PointNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbPm1WS7UWe6"
      },
      "source": [
        "This is an implementation of [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593) using PyTorch.\n",
        "\n",
        "Reference: [Deep Learning on Point clouds - Towards Data Science](https://towardsdatascience.com/deep-learning-on-point-clouds-implementing-pointnet-in-google-colab-1fd65cd3a263)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z7n_pw4SMWl"
      },
      "source": [
        "## Getting started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGjwJhn0VTVu"
      },
      "source": [
        "Don't forget to turn on GPU if you want to start training directly.\n",
        "\n",
        "\n",
        "**Runtime** -> **Change runtime type**-> **Hardware accelerator**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ47VNF7fmTS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import scipy.spatial.distance\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpzTlKjmlr2q"
      },
      "outputs": [],
      "source": [
        "random.seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg6HhI7eU80o"
      },
      "source": [
        "Download the [dataset](http://3dvision.princeton.edu/projects/2014/3DShapeNets/) directly to the Google Colab Runtime. It comprises 10 categories, 3,991 models for training and 908 for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup path to data folder\n",
        "data_path = Path(\"dataset/\")\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if data_path.is_dir():\n",
        "    print(f\"{data_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {data_path} directory, creating one...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download ModelNet10\n",
        "    with open(data_path / \"ModelNet10.zip\", \"wb\") as f:\n",
        "        print(\"Downloading ModelNet10 data...\")\n",
        "        request = requests.get(\"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip ModelNet10\n",
        "    with zipfile.ZipFile(data_path / \"ModelNet10.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping ModelNet10 data...\") \n",
        "        zip_ref.extractall(data_path)\n",
        "\n",
        "    # Remove zip file\n",
        "    print(\"Removing zip file...\")\n",
        "    os.remove(data_path / \"ModelNet10.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyu78RWIQEQJ"
      },
      "outputs": [],
      "source": [
        "path = Path(\"dataset/ModelNet10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2i_0ECIcR1X",
        "outputId": "e88a7341-e24b-459e-f496-1f5c99ae1232"
      },
      "outputs": [],
      "source": [
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)};\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krbtoQtTXOBa"
      },
      "source": [
        "This dataset consists ofÂ **.off** files that contain meshes represented by *vertices* and *triangular faces*.\n",
        "\n",
        "We will need a function to read this type of files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXEzgwr_Mfc0"
      },
      "outputs": [],
      "source": [
        "def read_off(file):\n",
        "    if 'OFF' != file.readline().strip():\n",
        "        raise('Not a valid OFF header')\n",
        "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
        "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
        "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
        "    return verts, faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddne6NHcPIHn"
      },
      "outputs": [],
      "source": [
        "with open(path/\"bed/train/bed_0001.off\", 'r') as f:\n",
        "  verts, faces = read_off(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpH2NKXNlPl4"
      },
      "outputs": [],
      "source": [
        "i,j,k = np.array(faces).T\n",
        "x,y,z = np.array(verts).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le4-KXs1j1E3",
        "outputId": "dad0f6e7-7298-4570-de46-e9d8a2dc5cfc"
      },
      "outputs": [],
      "source": [
        "len(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2XqwjkJXqLE"
      },
      "source": [
        "Don't be scared of this function. It's just to display animated rotation of meshes and point clouds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dbIQBLykGpX"
      },
      "outputs": [],
      "source": [
        "def visualize_rotate(data):\n",
        "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
        "    frames=[]\n",
        "\n",
        "    def rotate_z(x, y, z, theta):\n",
        "        w = x+1j*y\n",
        "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
        "\n",
        "    for t in np.arange(0, 10.26, 0.1):\n",
        "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
        "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
        "    fig = go.Figure(data=data,\n",
        "                    layout=go.Layout(\n",
        "                        updatemenus=[dict(type='buttons',\n",
        "                                    showactive=False,\n",
        "                                    y=1,\n",
        "                                    x=0.8,\n",
        "                                    xanchor='left',\n",
        "                                    yanchor='bottom',\n",
        "                                    pad=dict(t=45, r=10),\n",
        "                                    buttons=[dict(label='Play',\n",
        "                                                    method='animate',\n",
        "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
        "                                                                    transition=dict(duration=0),\n",
        "                                                                    fromcurrent=True,\n",
        "                                                                    mode='immediate'\n",
        "                                                                    )]\n",
        "                                                    )\n",
        "                                            ]\n",
        "                                    )\n",
        "                                ]\n",
        "                    ),\n",
        "                    frames=frames\n",
        "            )\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0huQ5maYxBa9",
        "outputId": "890250cf-1a4e-4bba-cac5-aa409b090c6e"
      },
      "outputs": [],
      "source": [
        "visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpGrWndRVYw"
      },
      "source": [
        "This mesh definitely looks like a bed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "y9hL_IOoMVzP",
        "outputId": "2cc0e2b0-11df-437c-c49c-56ff9ef6f652"
      },
      "outputs": [],
      "source": [
        "visualize_rotate([go.Scatter3d(x=x, y=y, z=z,\n",
        "                                   mode='markers')]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah0LVBEBRaGS"
      },
      "source": [
        "Unfortunately, that's not the case for its vertices. It would be difficult for PointNet to classify point clouds like this one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBNJ__37RBvi"
      },
      "source": [
        "First things first, let's write a function to accurately visualize point clouds so we could see vertices better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VovK365pQ12G"
      },
      "outputs": [],
      "source": [
        "def pcshow(xs,ys,zs):\n",
        "    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
        "                                   mode='markers')]\n",
        "    fig = visualize_rotate(data)\n",
        "    fig.update_traces(marker=dict(size=2,\n",
        "                      line=dict(width=2,\n",
        "                      color='DarkSlateGrey')),\n",
        "                      selector=dict(mode='markers'))\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "h6CRZdE2Qw5J",
        "outputId": "e68c911b-5efe-4dca-ba37-7c7ccdeffb32"
      },
      "outputs": [],
      "source": [
        "pcshow(x,y,z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axdsyO0wWZEB"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tJZHWppZ85P"
      },
      "source": [
        "As we want it to look more like a real bed, let's write a function to sample points on the surface uniformly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pee3OqfyhSdt"
      },
      "source": [
        " ### Sample points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCgPQhfvh7R3"
      },
      "outputs": [],
      "source": [
        "class PointSampler(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def triangle_area(self, pt1, pt2, pt3):\n",
        "        side_a = np.linalg.norm(pt1 - pt2)\n",
        "        side_b = np.linalg.norm(pt2 - pt3)\n",
        "        side_c = np.linalg.norm(pt3 - pt1)\n",
        "        s = 0.5 * ( side_a + side_b + side_c)\n",
        "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "    def sample_point(self, pt1, pt2, pt3):\n",
        "        # barycentric coordinates on a triangle\n",
        "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "        s, t = sorted([random.random(), random.random()])\n",
        "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "        return (f(0), f(1), f(2))\n",
        "\n",
        "\n",
        "    def __call__(self, mesh):\n",
        "        verts, faces = mesh\n",
        "        verts = np.array(verts)\n",
        "        areas = np.zeros((len(faces)))\n",
        "\n",
        "        for i in range(len(areas)):\n",
        "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
        "                                           verts[faces[i][1]],\n",
        "                                           verts[faces[i][2]]))\n",
        "\n",
        "        sampled_faces = (random.choices(faces,\n",
        "                                      weights=areas,\n",
        "                                      cum_weights=None,\n",
        "                                      k=self.output_size))\n",
        "\n",
        "        sampled_points = np.zeros((self.output_size, 3))\n",
        "\n",
        "        for i in range(len(sampled_faces)):\n",
        "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
        "                                                   verts[sampled_faces[i][1]],\n",
        "                                                   verts[sampled_faces[i][2]]))\n",
        "\n",
        "        return sampled_points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwg7LG6mkzgN"
      },
      "outputs": [],
      "source": [
        "pointcloud = PointSampler(3000)((verts, faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "m5sSdqp-iTuA",
        "outputId": "edd3cbb2-21d0-45d4-87c9-195cc2293a9d"
      },
      "outputs": [],
      "source": [
        "pcshow(*pointcloud.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ZsXeLOrFTT"
      },
      "source": [
        "This pointcloud looks much more like a bed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXU9PdRqbbBx"
      },
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCduIRX6uiDs"
      },
      "source": [
        "Unit sphere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR3r0WPdWbHN"
      },
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfMnH_o8aIWe"
      },
      "outputs": [],
      "source": [
        "norm_pointcloud = Normalize()(pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "4fGlqqqjaQGF",
        "outputId": "153c3393-9503-4187-a147-c32c0d3fc65d"
      },
      "outputs": [],
      "source": [
        "pcshow(*norm_pointcloud.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTz_SFrDhezz"
      },
      "source": [
        "Notice that axis limits have changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LtFfliNuxw3"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbYrmnasZAUg"
      },
      "source": [
        "Let's add *random rotation* of the whole pointcloud and random noise to its points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHAvoR7wuwS6"
      },
      "outputs": [],
      "source": [
        "class RandRotation_z(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        theta = random.random() * 2. * math.pi\n",
        "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "                               [ math.sin(theta),  math.cos(theta),    0],\n",
        "                               [0,                             0,      1]])\n",
        "\n",
        "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "        return  rot_pointcloud\n",
        "\n",
        "class RandomNoise(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "\n",
        "        noisy_pointcloud = pointcloud + noise\n",
        "        return  noisy_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aektc3DZwbc9"
      },
      "outputs": [],
      "source": [
        "rot_pointcloud = RandRotation_z()(norm_pointcloud)\n",
        "noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "GcLIa7KmweAL",
        "outputId": "2e6b612d-73d3-48a6-c9a8-51bdf3e6565e"
      },
      "outputs": [],
      "source": [
        "pcshow(*noisy_rot_pointcloud.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE6QmxhRbwsY"
      },
      "source": [
        "### ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctHIvE-Kbr-m"
      },
      "outputs": [],
      "source": [
        "class ToTensor(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        return torch.from_numpy(pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7FK8nVrel4z",
        "outputId": "07bb3f89-4789-4c39-9bbf-dc67f2834229"
      },
      "outputs": [],
      "source": [
        "ToTensor()(noisy_rot_pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdQhWT4Q1GbF"
      },
      "outputs": [],
      "source": [
        "def default_transforms():\n",
        "    return transforms.Compose([\n",
        "                                PointSampler(1024),\n",
        "                                Normalize(),\n",
        "                                ToTensor()\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMIT1MeNSSO8"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sl3iM3CZM5n"
      },
      "source": [
        "Now we can create a [custom PyTorch Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i06OYFNR8fa_"
      },
      "outputs": [],
      "source": [
        "class PointCloudData(Dataset):\n",
        "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
        "        self.root_dir = root_dir\n",
        "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "        self.transforms = transform if not valid else default_transforms()\n",
        "        self.valid = valid\n",
        "        self.files = []\n",
        "        for category in self.classes.keys():\n",
        "            new_dir = root_dir/Path(category)/folder\n",
        "            for file in os.listdir(new_dir):\n",
        "                if file.endswith('.off'):\n",
        "                    sample = {}\n",
        "                    sample['pcd_path'] = new_dir/file\n",
        "                    sample['category'] = category\n",
        "                    self.files.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __preproc__(self, file):\n",
        "        verts, faces = read_off(file)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms((verts, faces))\n",
        "        return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files[idx]['pcd_path']\n",
        "        category = self.files[idx]['category']\n",
        "        with open(pcd_path, 'r') as f:\n",
        "            pointcloud = self.__preproc__(f)\n",
        "        return {'pointcloud': pointcloud,\n",
        "                'category': self.classes[category]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOEaUDwzZY3v"
      },
      "source": [
        "Transforms for training. 1024 points per cloud as in the paper!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pOl95glmphX"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                    PointSampler(1024),\n",
        "                    Normalize(),\n",
        "                    RandRotation_z(),\n",
        "                    RandomNoise(),\n",
        "                    ToTensor()\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpDsEx00mZrx"
      },
      "outputs": [],
      "source": [
        "train_ds = PointCloudData(path, transform=train_transforms)\n",
        "valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbIZKqkIrdQE",
        "outputId": "24d122ab-bfdb-4a9d-c3d0-9cfd9fb450bc"
      },
      "outputs": [],
      "source": [
        "inv_classes = {i: cat for cat, i in train_ds.classes.items()};\n",
        "inv_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arTK45IlBeiZ",
        "outputId": "38f12cf3-333b-4329-99bf-b9cca5d87dfa"
      },
      "outputs": [],
      "source": [
        "print('Train dataset size: ', len(train_ds))\n",
        "print('Valid dataset size: ', len(valid_ds))\n",
        "print('Number of classes: ', len(train_ds.classes))\n",
        "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n",
        "print('Class: ', inv_classes[train_ds[0]['category']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVGtKLa4PthS"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_ds, batch_size=512, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_ds, batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isb_97zOA8Tl"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7YJxkSE9cGV"
      },
      "source": [
        "What is shared weights?\n",
        "\n",
        "A CNN has multiple layers. Weight sharing happens across the receptive field of the neurons(filters) in a particular layer.Weights are the numbers within each filter. So essentially we are trying to learn a filter. These filters act on a certain receptive field/ small section of the image. When the filter moves through the image, the filter does not change. The idea being, if an edge is important to learn in a particular part of an image, it is important in other parts of the image too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV20opgrv23I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Tnet(nn.Module):\n",
        "   def __init__(self, k=3):\n",
        "      super().__init__()\n",
        "      self.k=k\n",
        "      self.conv1 = nn.Conv1d(in_channels=k, out_channels=64, kernel_size=1) # In 1D conv, if in_channels are less then out_channels, then it increases the number of channels\n",
        "      self.conv2 = nn.Conv1d(64,128,1)\n",
        "      self.conv3 = nn.Conv1d(128,1024,1)\n",
        "      self.fc1 = nn.Linear(1024,512)\n",
        "      self.fc2 = nn.Linear(512,256)\n",
        "      self.fc3 = nn.Linear(256,k*k)\n",
        "\n",
        "      self.bn1 = nn.BatchNorm1d(64)\n",
        "      self.bn2 = nn.BatchNorm1d(128)\n",
        "      self.bn3 = nn.BatchNorm1d(1024)\n",
        "      self.bn4 = nn.BatchNorm1d(512)\n",
        "      self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "   def forward(self, input):\n",
        "      # input.shape == (bs,n,3)\n",
        "      bs = input.size(0)\n",
        "      xb = F.relu(self.bn1(self.conv1(input)))\n",
        "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
        "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "      flat = nn.Flatten(1)(pool)\n",
        "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
        "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
        "\n",
        "      #initialize as identity\n",
        "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "      if xb.is_cuda:\n",
        "        init=init.cuda()\n",
        "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "      return matrix\n",
        "\n",
        "\n",
        "class Transform(nn.Module):\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_transform = Tnet(k=3)\n",
        "        self.feature_transform = Tnet(k=64)\n",
        "        self.conv1 = nn.Conv1d(3,64,1)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64,128,1)\n",
        "        self.conv3 = nn.Conv1d(128,1024,1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "\n",
        "   def forward(self, input):\n",
        "        matrix3x3 = self.input_transform(input)\n",
        "        # batch matrix multiplication\n",
        "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
        "\n",
        "        matrix64x64 = self.feature_transform(xb)\n",
        "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "        xb = self.bn3(self.conv3(xb))\n",
        "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "        output = nn.Flatten(1)(xb)\n",
        "        return output, matrix3x3, matrix64x64\n",
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self, classes = 10):\n",
        "        super().__init__()\n",
        "        self.transform = Transform()\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, classes)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
        "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
        "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
        "        output = self.fc3(xb)\n",
        "        return self.logsoftmax(output), matrix3x3, matrix64x64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "580NErhyP1zD"
      },
      "outputs": [],
      "source": [
        "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    bs=outputs.size(0)\n",
        "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
        "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
        "    if outputs.is_cuda:\n",
        "        id3x3=id3x3.cuda()\n",
        "        id64x64=id64x64.cuda()\n",
        "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
        "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
        "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mLBRcfwP2Sq"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUJOEaWdmsRD"
      },
      "source": [
        "You can find a pretrained model [here](https://drive.google.com/open?id=1nDG0maaqoTkRkVsOLtUAR9X3kn__LMSL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvmmwhcePvt2",
        "outputId": "c1e6ac47-e4b9-4ee7-d358-55f83dc2137c"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_DXKkfMPxP0"
      },
      "outputs": [],
      "source": [
        "pointnet = PointNet()\n",
        "pointnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ST7F9E5P0BI"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg8obt6FP6Ff"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
        "    for epoch in range(epochs):\n",
        "        pointnet.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in tqdm(enumerate(train_loader, 0)):\n",
        "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
        "\n",
        "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # print every 10 mini-batches\n",
        "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
        "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        pointnet.eval()\n",
        "        correct = total = 0\n",
        "\n",
        "        # validation\n",
        "        if val_loader:\n",
        "            with torch.no_grad():\n",
        "                for data in val_loader:\n",
        "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "            val_acc = 100. * correct / total\n",
        "            print('Valid accuracy: %d %%' % val_acc)\n",
        "\n",
        "        # save the model\n",
        "        if save:\n",
        "            torch.save(pointnet.state_dict(), \"save_\"+str(epoch)+\".pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp3uFKomP8AU",
        "outputId": "9cdcd045-bfb3-4ce5-cc11-47987ee15715"
      },
      "outputs": [],
      "source": [
        "train(pointnet, train_loader, valid_loader,  save=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8W4gOI_P9a9"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iDtAJoYH4hE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU70YWA7P-I_"
      },
      "outputs": [],
      "source": [
        "pointnet = PointNet()\n",
        "pointnet.load_state_dict(torch.load('save.pth'))\n",
        "pointnet.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54EP7PAyC2iQ",
        "outputId": "a9469e95-2943-40f8-c699-b4031b6f9811"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(valid_loader):\n",
        "        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
        "\n",
        "        inputs, labels = data['pointcloud'].float(), data['category']\n",
        "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        all_preds += list(preds.numpy())\n",
        "        all_labels += list(labels.numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWNts-GKELNk",
        "outputId": "7ec6b478-a063-4313-823c-4e3a8150e01a"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(all_labels, all_preds);\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcS7dXw5Rkae"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "Vg-hPQ8ERpj7",
        "outputId": "1c83b893-3070-4ea9-c30c-eae63a5b0102"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plot_confusion_matrix(cm, list(classes.keys()), normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "BwRxAddUVxHT",
        "outputId": "c535d484-2823-44c8-aa7f-bfd11c2f1c0f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plot_confusion_matrix(cm, list(classes.keys()), normalize=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AE6QmxhRbwsY",
        "mMIT1MeNSSO8",
        "Isb_97zOA8Tl",
        "_8W4gOI_P9a9"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
